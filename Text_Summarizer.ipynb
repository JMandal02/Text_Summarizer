{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPL1t1X/Vm837UVFsDUIish",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JMandal02/Text_Summarizer/blob/main/Text_Summarizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# networkx: Creating and manipulating complex networks (e.g., word networks)\n",
        "import networkx as nx\n",
        "# matplotlib.pyplot: Generating visualizations (e.g., plotting graphs)\n",
        "import matplotlib.pyplot as plt\n",
        "# nltk: Core Natural Language Toolkit library\n",
        "import nltk\n",
        "# Download the 'stopwords' dataset\n",
        "nltk.download('stopwords')\n",
        "# nltk.corpus.stopwords: Accessing a list of common words to remove from text\n",
        "from nltk.corpus import stopwords\n",
        "# nltk.tokenize: Splitting text into words and sentences\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "# nltk.cluster.util: Calculating cosine distance for text similarity\n",
        "from nltk.cluster.util import cosine_distance\n",
        "# numpy: Numerical computing with arrays and matrices\n",
        "import numpy as np\n",
        "# re: Working with regular expressions for pattern matching\n",
        "import re\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPdxNd0axeGF",
        "outputId": "0f2d6cc3-84e6-4b6f-ac4b-de00af54766c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_article(file_name):\n",
        "    with open(file_name, \"r\", encoding=\"utf-8\") as file:\n",
        "        filedata = file.read()\n",
        "    article = filedata.split(\". \")  # Splitting the entire content\n",
        "    sentences = [sentence.replace(\"[^a-zA-Z]\", \" \").split(\" \") for sentence in article]\n",
        "    return sentences\n"
      ],
      "metadata": {
        "id": "tXcfH3rlFG8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function is designed to calculate the **similarity** between two sentences using cosine similarity."
      ],
      "metadata": {
        "id": "NgfClK420jv_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence_similarity(sent1, sent2, stopwords=None):\n",
        "    if stopwords is None:\n",
        "        stopwords = []\n",
        "\n",
        "    # These lines convert the sentences to lowercase to ensure case-insensitive comparison.\n",
        "    sent1 = [w.lower() for w in sent1]\n",
        "    sent2 = [w.lower() for w in sent2]\n",
        "\n",
        "    # This line creates a list of all unique words in both sentences.\n",
        "    all_words = list(set(sent1 + sent2))\n",
        "\n",
        "    # These lines initialize two vectors to store word frequencies for each sentence.\n",
        "    vactor1 = [0] * len(all_words)\n",
        "    vactor2 = [0] * len(all_words)\n",
        "\n",
        "    # This loop iterates through each word in the first sentence.\n",
        "    for w in sent1:\n",
        "        if w in stopwords:\n",
        "            continue\n",
        "        vactor1[all_words.index(w)] += 1\n",
        "\n",
        "    # This loop does the same for the second sentence.\n",
        "    for w in sent2:\n",
        "        if w in stopwords:\n",
        "            continue\n",
        "        vactor2[all_words.index(w)] += 1\n",
        "\n",
        "    # This line calculates and returns the cosine similarity between the two vectors.\n",
        "    return 1 - cosine_distance(vactor1, vactor2)"
      ],
      "metadata": {
        "id": "GHmt4Hux2CXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function is crucial for text summarization as it creates a similarity matrix.\n",
        "    This matrix quantifies the relationships between each sentence in the text.\n",
        "    "
      ],
      "metadata": {
        "id": "XbMSy7B84zKh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_similarity_matrix(sentences, stop_words):\n",
        "\n",
        "    # Initialize an empty similarity matrix with dimensions equal to the number of sentences.\n",
        "    similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
        "\n",
        "    for idx1 in range(len(sentences)):\n",
        "        for idx2 in range(len(sentences)):\n",
        "            if idx1 == idx2: #ignore if both are same sentences\n",
        "                continue\n",
        "            similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2], stop_words)\n",
        "\n",
        "    return similarity_matrix\n"
      ],
      "metadata": {
        "id": "9bWfRqi3466o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " This function is the core of the text summarization process."
      ],
      "metadata": {
        "id": "iVNFqOgS6gfl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_summary(file_name, top_n=5):\n",
        "    stop_words = stopwords.words('english')\n",
        "    summarize_text = []\n",
        "\n",
        "    sentences = read_article(file_name)\n",
        "\n",
        "    # Check if the article contains any sentences.\n",
        "    if not sentences:\n",
        "        print(\"No sentences found in the text file.\")\n",
        "        return []\n",
        "\n",
        "    # Build a similarity matrix between sentences.\n",
        "    sentence_similarity_matrix = build_similarity_matrix(sentences, stop_words)\n",
        "    sentence_similarity_graph = nx.from_numpy_array(sentence_similarity_matrix)\n",
        "    scores = nx.pagerank(sentence_similarity_graph)\n",
        "\n",
        "     # Sort sentences based on their PageRank scores in descending order.\n",
        "    ranked_sentence = sorted(((scores[i], s) for i, s in enumerate(sentences)), reverse=True)\n",
        "\n",
        "    # Extract the top 'top_n' ranked sentences for the summary.\n",
        "    for i in range(min(top_n, len(ranked_sentence))):\n",
        "        summarize_text.append(\" \".join(ranked_sentence[i][1]))\n",
        "\n",
        "    return summarize_text\n"
      ],
      "metadata": {
        "id": "I73Q1SMzBV5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the file path from the user.\n",
        "file_path = input(\"Enter the path to the text file: \")\n",
        "\n",
        "# Use a try-except block to handle potential errors when getting the number of sentences.\n",
        "try:\n",
        "    top_n = int(input(\"Enter the number of sentences for the summary: \"))\n",
        "    if top_n <= 0:\n",
        "        print(\"Please enter a positive integer for the number of sentences.\")\n",
        "    else:\n",
        "        summary = generate_summary(file_path, top_n)\n",
        "        print(\"\\nGenerated Summary:\\n\", \" \".join(summary))\n",
        "\n",
        "# Handle ValueError, which occurs if the user enters non-numeric input for 'top_n'.\n",
        "except ValueError:\n",
        "    print(\"Invalid input. Please enter a valid integer for the number of sentences.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWRtl737-UTs",
        "outputId": "b3bd2d7f-46e1-4bb1-f135-e318e44ee5f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the path to the text file: /content/Introduction to Machine Learning.txt\n",
            "Enter the number of sentences for the summary: 10\n",
            "\n",
            "Generated Summary:\n",
            " It uses statistical techniques to improve performance on a task over time.\n",
            "Types of Machine Learning\n",
            "Supervised Learning: The model learns from labeled data, making predictions based on input-output pairs Examples include spam detection and image classification.\n",
            "Unsupervised Learning: The model identifies patterns in unlabeled data, such as clustering customers for marketing.\n",
            "Reinforcement Learning: The model learns by interacting with an environment and receiving rewards or penalties It is used in robotics and game AI.\n",
            "Applications of Machine Learning\n",
            "ML is widely used in healthcare (disease prediction), finance (fraud detection), autonomous vehicles, recommendation systems (Netflix, Amazon), and speech recognition (Siri, Google Assistant).\n",
            "Challenges in Machine Learning\n",
            "Challenges include data quality, model interpretability, overfitting, and computational costs Introduction to Machine Learning\n",
            "Machine learning (ML) is a branch of artificial intelligence that enables computers to learn from data without explicit programming Ethical concerns like bias and privacy are also crucial considerations.\n",
            "Conclusion\n",
            "Machine learning is transforming industries by enabling data-driven decision-making With advancements in algorithms and computing power, its impact will continue to grow.\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}